{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with george\n",
    "\n",
    "One of the `tinygp` design decisions was to provide a high-level API similar to the one provided by the [george](https://george.readthedocs.io) GP library.\n",
    "This was partly because I (as the lead developer of `george`) wanted to ease users' transitions away from `george` to something more modern (like `tinygp`).\n",
    "I also quite like the `george` API and don't think that there exist other similar tools.\n",
    "The defining feature is `tinygp` does not include built-in implementations of inference algorithms.\n",
    "Instead, it provides an expressive model-building interface that makes it easy to experiement with different kernels while still integrating with your favorite inference engine.\n",
    "\n",
    "In this document, we compare the interfaces and computational performance of `george` and `tinygp` for constructing kernel models and evaluating the GP marginalized likelihood.\n",
    "Since `tinygp` supports GPU-acceleration, we have executed this notebook on a machine with a GPU with the following specs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the CPU versions of both `george` and `tinygp` will also use parellelized linear algebra libraries to take advantage of multiple CPU threads, however to make the benchmarks more replicable, we'll disable this parallelization for the remainder of this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"XLA_FLAGS\"] = (\n",
    "    os.environ.get(\"XLA_FLAGS\", \"\")\n",
    "    + \" --xla_cpu_multi_thread_eigen=false intra_op_parallelism_threads=1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we generate some simulated data and define functions for computing the GP log likelihood using `george` and `tinygp` (with separate CPU and GPU version).\n",
    "As mentioned above, the syntax of these functions is quite similar, but there are a few differences.\n",
    "Most notably, the units of the \"metric\" or \"length scale\" parameter in the kernel is different (length-squared in `george` and not squared in `tinygp`).\n",
    "Also, the `gp.compute` method no longer exists in `tinygp` since this would be less compatible with `jax`'s preference for pure functional programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import tinygp\n",
    "except ImportError:\n",
    "    !pip install -q tinygp\n",
    "\n",
    "try:\n",
    "    import george\n",
    "except ImportError:\n",
    "    !pip install -q george"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "from jax import config\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import george\n",
    "import tinygp\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "sigma = 1.5\n",
    "rho = 2.5\n",
    "jitter = 0.1\n",
    "\n",
    "random = np.random.default_rng(49382)\n",
    "x = np.sort(random.uniform(0, 10, 10_000))\n",
    "y = np.sin(x) + jitter * random.normal(0, 1, len(x))\n",
    "\n",
    "\n",
    "def george_loglike(x, y, **kwargs):\n",
    "    kernel = sigma ** 2 * george.kernels.Matern32Kernel(rho ** 2)\n",
    "    gp = george.GP(kernel, **kwargs)\n",
    "    gp.compute(x, jitter)\n",
    "    return gp.log_likelihood(y)\n",
    "\n",
    "\n",
    "def tinygp_loglike(x, y):\n",
    "    kernel = sigma ** 2 * tinygp.kernels.Matern32(rho)\n",
    "    gp = tinygp.GaussianProcess(kernel, x, diag=jitter ** 2)\n",
    "    return gp.condition(y)\n",
    "\n",
    "\n",
    "hodlr_loglike = partial(\n",
    "    george_loglike, solver=george.solvers.HODLRSolver, tol=0.5\n",
    ")\n",
    "tinygp_loglike_cpu = jax.jit(tinygp_loglike, backend=\"cpu\")\n",
    "tinygp_loglike_gpu = jax.jit(tinygp_loglike, backend=\"gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we benchmark the computational cost of computing the log likelihood using each of these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [10, 100, 1_000, 10_000]\n",
    "george_time = []\n",
    "hodlr_time = []\n",
    "cpu_time = []\n",
    "gpu_time = []\n",
    "for n in ns:\n",
    "    print(f\"N = {n}:\")\n",
    "\n",
    "    # Run the JAX versions once each to make sure they get JIT'd\n",
    "    args = x[:n], y[:n]\n",
    "    tinygp_loglike_cpu(*args).block_until_ready()\n",
    "    tinygp_loglike_gpu(*args).block_until_ready()\n",
    "    \n",
    "    results = %timeit -o george_loglike(*args)\n",
    "    george_time.append(results.average)\n",
    "\n",
    "    results = %timeit -o hodlr_loglike(*args)\n",
    "    hodlr_time.append(results.average)\n",
    "    \n",
    "    results = %timeit -o tinygp_loglike_cpu(*args).block_until_ready()\n",
    "    cpu_time.append(results.average)\n",
    "    \n",
    "    results = %timeit -o tinygp_loglike_gpu(*args).block_until_ready()\n",
    "    gpu_time.append(results.average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot of this benchmark, you'll notice several features:\n",
    "\n",
    "1. For very small datasets, the `tinygp` CPU implementation is significantly faster than any of the other implementations. This is because `jax.jit` removes a lot of the Python overhead that is encountered when chaining `numpy` functions.\n",
    "2. For medium to large datasets, `tinygp` is generally faster than `george`, with the GPU version seeing a significant advantage.\n",
    "3. The CPU implementations approach the expected asymptotic complexity of $\\mathcal{O}(N^3)$ only for the largest values of $N$. This is probably caused by memory allocation overhead or other operations with better scaling than the Cholesky factorization.\n",
    "4. The approximate \"HODLR\" solver from `george` outperforms the GPU-enabled `tinygp` exact solver, but only for very large datasets, and it's important to note that the HODLR method does not scale well to larger input dimensions. Any existing or future approximate solvers like this that are implemented in `jax` could be easily used in conjunction with `tinygp`, but such things have not yet been implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(ns, george_time, \"o-\", label=\"george (basic)\")\n",
    "plt.loglog(ns, hodlr_time, \"o-\", label=\"george (HODLR)\")\n",
    "plt.loglog(ns, cpu_time, \"o-\", label=\"tinygp (CPU)\")\n",
    "plt.loglog(ns, gpu_time, \"o-\", label=\"tinygp (GPU)\")\n",
    "ylim = plt.ylim()\n",
    "plt.loglog(\n",
    "    ns,\n",
    "    0.5 * np.array(ns) ** 3 / ns[-1] ** 3 * cpu_time[-1],\n",
    "    \":k\",\n",
    "    label=\"O($N^3$)\",\n",
    ")\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel(\"number of data points\")\n",
    "plt.ylabel(\"runtime [s]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinygp",
   "language": "python",
   "name": "tinygp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
